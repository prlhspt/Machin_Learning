{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive</th>\n",
       "      <th>svm</th>\n",
       "      <th>RF</th>\n",
       "      <th>DT</th>\n",
       "      <th>VT</th>\n",
       "      <th>lgbm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.776118</td>\n",
       "      <td>0.695035</td>\n",
       "      <td>0.50769</td>\n",
       "      <td>0.482873</td>\n",
       "      <td>0.723579</td>\n",
       "      <td>0.606612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Naive       svm       RF        DT        VT      lgbm\n",
       "0  0.776118  0.695035  0.50769  0.482873  0.723579  0.606612"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Naive' : [Naive], 'svm':[svm], 'RF':[RF], 'DT':[DT], 'VT':[VT], 'lgbm':[lgbm]})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "train_news= fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), random_state=156)\n",
    "X_train = train_news.data\n",
    "y_train = train_news.target\n",
    "\n",
    "test_news=fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), random_state=156)\n",
    "X_test = test_news.data\n",
    "y_test = test_news.target\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(stop_words = 'english', ngram_range=(1, 2), max_df = 300)\n",
    "tfidf_vect.fit(X_train)\n",
    "\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터:\n",
      " {'alpha': 0.02}\n",
      "최고 예측 정확도: 0.7761\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mod = MultinomialNB()\n",
    "mod.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "param_grid = [{'alpha': np.linspace(0.01, 1, 100)}]\n",
    "gs = GridSearchCV(estimator=mod, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "gs.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "print('최적 하이퍼 파라미터:\\n', gs.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(gs.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7761182174472435"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Naive = gs.best_score_\n",
    "Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6950345193839618\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "pred = clf.predict(X_test_tfidf_vect) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, pred)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6950345193839618"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = accuracy_score(y_test, pred)\n",
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6344928305894849\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = rf_clf.predict(X_test_tfidf_vect)\n",
    "print(\"정확도:\", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6344928305894849"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = accuracy_score(y_test, pred)\n",
    "RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48287307488050984"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dcl = DecisionTreeClassifier()\n",
    "dcl.fit(X_train_tfidf_vect, y_train)\n",
    "pred = dcl.predict(X_test_tfidf_vect)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48287307488050984"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT = accuracy_score(y_test, pred)\n",
    "DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prlhspt/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting 분류기 정확도: 0.7236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "lr_clf = LogisticRegression(C=10)\n",
    "mod = MultinomialNB(alpha=0.02)\n",
    "\n",
    "# 개별 모델을 소프트 보팅 기반의 앙상블 모델로 구현한 분류기\n",
    "vo_clf = VotingClassifier(estimators=[('LR', lr_clf), ('MNB', mod)], voting='soft')\n",
    "\n",
    "#VotingClassifier 학습/예측/평가.\n",
    "vo_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = vo_clf.predict(X_test_tfidf_vect)\n",
    "print('Voting 분류기 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.723579394583112"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VT = accuracy_score(y_test, pred)\n",
    "VT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 12, 'min_samples_leaf': 8, 'min_samples_split': 8, 'n_estimators': 100}\n",
      "최고 예측 정확도: 0.5077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100],\n",
    "    'max_depth' : [6, 8, 10, 12], \n",
    "    'min_samples_leaf' : [8, 12, 18 ],\n",
    "    'min_samples_split' : [8, 16, 20]\n",
    "}\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(n_estimators=300, max_depth=10, min_samples_leaf=8, min_samples_split=8)\n",
    "                                \n",
    "rf_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "gs = GridSearchCV(rf_clf , param_grid=params , cv=2, n_jobs=-1 )\n",
    "gs.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "print('최적 하이퍼 파라미터:\\n', gs.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(gs.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5076895881209121"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = gs.best_score_\n",
    "RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 2.65668\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's multi_logloss: 2.48723\n",
      "[3]\tvalid_0's multi_logloss: 2.36954\n",
      "[4]\tvalid_0's multi_logloss: 2.2785\n",
      "[5]\tvalid_0's multi_logloss: 2.20352\n",
      "[6]\tvalid_0's multi_logloss: 2.13914\n",
      "[7]\tvalid_0's multi_logloss: 2.0848\n",
      "[8]\tvalid_0's multi_logloss: 2.0363\n",
      "[9]\tvalid_0's multi_logloss: 1.99262\n",
      "[10]\tvalid_0's multi_logloss: 1.95501\n",
      "[11]\tvalid_0's multi_logloss: 1.91861\n",
      "[12]\tvalid_0's multi_logloss: 1.88612\n",
      "[13]\tvalid_0's multi_logloss: 1.85603\n",
      "[14]\tvalid_0's multi_logloss: 1.8301\n",
      "[15]\tvalid_0's multi_logloss: 1.80479\n",
      "[16]\tvalid_0's multi_logloss: 1.78296\n",
      "[17]\tvalid_0's multi_logloss: 1.76189\n",
      "[18]\tvalid_0's multi_logloss: 1.74225\n",
      "[19]\tvalid_0's multi_logloss: 1.72441\n",
      "[20]\tvalid_0's multi_logloss: 1.70714\n",
      "[21]\tvalid_0's multi_logloss: 1.69203\n",
      "[22]\tvalid_0's multi_logloss: 1.6767\n",
      "[23]\tvalid_0's multi_logloss: 1.66236\n",
      "[24]\tvalid_0's multi_logloss: 1.64854\n",
      "[25]\tvalid_0's multi_logloss: 1.63564\n",
      "[26]\tvalid_0's multi_logloss: 1.62385\n",
      "[27]\tvalid_0's multi_logloss: 1.61218\n",
      "[28]\tvalid_0's multi_logloss: 1.60208\n",
      "[29]\tvalid_0's multi_logloss: 1.59116\n",
      "[30]\tvalid_0's multi_logloss: 1.58126\n",
      "[31]\tvalid_0's multi_logloss: 1.57173\n",
      "[32]\tvalid_0's multi_logloss: 1.56403\n",
      "[33]\tvalid_0's multi_logloss: 1.55559\n",
      "[34]\tvalid_0's multi_logloss: 1.54734\n",
      "[35]\tvalid_0's multi_logloss: 1.53939\n",
      "[36]\tvalid_0's multi_logloss: 1.5321\n",
      "[37]\tvalid_0's multi_logloss: 1.52544\n",
      "[38]\tvalid_0's multi_logloss: 1.51845\n",
      "[39]\tvalid_0's multi_logloss: 1.51143\n",
      "[40]\tvalid_0's multi_logloss: 1.50488\n",
      "[41]\tvalid_0's multi_logloss: 1.49869\n",
      "[42]\tvalid_0's multi_logloss: 1.49317\n",
      "[43]\tvalid_0's multi_logloss: 1.48752\n",
      "[44]\tvalid_0's multi_logloss: 1.48208\n",
      "[45]\tvalid_0's multi_logloss: 1.47672\n",
      "[46]\tvalid_0's multi_logloss: 1.47231\n",
      "[47]\tvalid_0's multi_logloss: 1.46769\n",
      "[48]\tvalid_0's multi_logloss: 1.4635\n",
      "[49]\tvalid_0's multi_logloss: 1.45921\n",
      "[50]\tvalid_0's multi_logloss: 1.45502\n",
      "[51]\tvalid_0's multi_logloss: 1.45061\n",
      "[52]\tvalid_0's multi_logloss: 1.44745\n",
      "[53]\tvalid_0's multi_logloss: 1.44381\n",
      "[54]\tvalid_0's multi_logloss: 1.44015\n",
      "[55]\tvalid_0's multi_logloss: 1.43743\n",
      "[56]\tvalid_0's multi_logloss: 1.43421\n",
      "[57]\tvalid_0's multi_logloss: 1.43144\n",
      "[58]\tvalid_0's multi_logloss: 1.42807\n",
      "[59]\tvalid_0's multi_logloss: 1.42585\n",
      "[60]\tvalid_0's multi_logloss: 1.4231\n",
      "[61]\tvalid_0's multi_logloss: 1.42061\n",
      "[62]\tvalid_0's multi_logloss: 1.4179\n",
      "[63]\tvalid_0's multi_logloss: 1.41576\n",
      "[64]\tvalid_0's multi_logloss: 1.41378\n",
      "[65]\tvalid_0's multi_logloss: 1.41191\n",
      "[66]\tvalid_0's multi_logloss: 1.41019\n",
      "[67]\tvalid_0's multi_logloss: 1.40802\n",
      "[68]\tvalid_0's multi_logloss: 1.40672\n",
      "[69]\tvalid_0's multi_logloss: 1.40486\n",
      "[70]\tvalid_0's multi_logloss: 1.40221\n",
      "[71]\tvalid_0's multi_logloss: 1.40081\n",
      "[72]\tvalid_0's multi_logloss: 1.39941\n",
      "[73]\tvalid_0's multi_logloss: 1.39756\n",
      "[74]\tvalid_0's multi_logloss: 1.39653\n",
      "[75]\tvalid_0's multi_logloss: 1.39526\n",
      "[76]\tvalid_0's multi_logloss: 1.39392\n",
      "[77]\tvalid_0's multi_logloss: 1.39222\n",
      "[78]\tvalid_0's multi_logloss: 1.39118\n",
      "[79]\tvalid_0's multi_logloss: 1.39055\n",
      "[80]\tvalid_0's multi_logloss: 1.38938\n",
      "[81]\tvalid_0's multi_logloss: 1.38835\n",
      "[82]\tvalid_0's multi_logloss: 1.38774\n",
      "[83]\tvalid_0's multi_logloss: 1.38657\n",
      "[84]\tvalid_0's multi_logloss: 1.38573\n",
      "[85]\tvalid_0's multi_logloss: 1.38427\n",
      "[86]\tvalid_0's multi_logloss: 1.38368\n",
      "[87]\tvalid_0's multi_logloss: 1.38341\n",
      "[88]\tvalid_0's multi_logloss: 1.38205\n",
      "[89]\tvalid_0's multi_logloss: 1.3813\n",
      "[90]\tvalid_0's multi_logloss: 1.3814\n",
      "[91]\tvalid_0's multi_logloss: 1.38065\n",
      "[92]\tvalid_0's multi_logloss: 1.38039\n",
      "[93]\tvalid_0's multi_logloss: 1.37991\n",
      "[94]\tvalid_0's multi_logloss: 1.37964\n",
      "[95]\tvalid_0's multi_logloss: 1.37913\n",
      "[96]\tvalid_0's multi_logloss: 1.37906\n",
      "[97]\tvalid_0's multi_logloss: 1.37902\n",
      "[98]\tvalid_0's multi_logloss: 1.37844\n",
      "[99]\tvalid_0's multi_logloss: 1.37887\n",
      "[100]\tvalid_0's multi_logloss: 1.37848\n",
      "[101]\tvalid_0's multi_logloss: 1.37807\n",
      "[102]\tvalid_0's multi_logloss: 1.37834\n",
      "[103]\tvalid_0's multi_logloss: 1.37819\n",
      "[104]\tvalid_0's multi_logloss: 1.37803\n",
      "[105]\tvalid_0's multi_logloss: 1.37738\n",
      "[106]\tvalid_0's multi_logloss: 1.37778\n",
      "[107]\tvalid_0's multi_logloss: 1.37791\n",
      "[108]\tvalid_0's multi_logloss: 1.37809\n",
      "[109]\tvalid_0's multi_logloss: 1.37807\n",
      "[110]\tvalid_0's multi_logloss: 1.37866\n",
      "[111]\tvalid_0's multi_logloss: 1.37867\n",
      "[112]\tvalid_0's multi_logloss: 1.3786\n",
      "[113]\tvalid_0's multi_logloss: 1.37871\n",
      "[114]\tvalid_0's multi_logloss: 1.3789\n",
      "[115]\tvalid_0's multi_logloss: 1.37925\n",
      "[116]\tvalid_0's multi_logloss: 1.37975\n",
      "[117]\tvalid_0's multi_logloss: 1.37984\n",
      "[118]\tvalid_0's multi_logloss: 1.38001\n",
      "[119]\tvalid_0's multi_logloss: 1.38029\n",
      "[120]\tvalid_0's multi_logloss: 1.38087\n",
      "[121]\tvalid_0's multi_logloss: 1.38135\n",
      "[122]\tvalid_0's multi_logloss: 1.38169\n",
      "[123]\tvalid_0's multi_logloss: 1.38203\n",
      "[124]\tvalid_0's multi_logloss: 1.38248\n",
      "[125]\tvalid_0's multi_logloss: 1.38303\n",
      "[126]\tvalid_0's multi_logloss: 1.38381\n",
      "[127]\tvalid_0's multi_logloss: 1.38376\n",
      "[128]\tvalid_0's multi_logloss: 1.38437\n",
      "[129]\tvalid_0's multi_logloss: 1.38454\n",
      "[130]\tvalid_0's multi_logloss: 1.38482\n",
      "[131]\tvalid_0's multi_logloss: 1.38581\n",
      "[132]\tvalid_0's multi_logloss: 1.38631\n",
      "[133]\tvalid_0's multi_logloss: 1.3868\n",
      "[134]\tvalid_0's multi_logloss: 1.38734\n",
      "[135]\tvalid_0's multi_logloss: 1.38782\n",
      "[136]\tvalid_0's multi_logloss: 1.38821\n",
      "[137]\tvalid_0's multi_logloss: 1.38887\n",
      "[138]\tvalid_0's multi_logloss: 1.38985\n",
      "[139]\tvalid_0's multi_logloss: 1.38977\n",
      "[140]\tvalid_0's multi_logloss: 1.39059\n",
      "[141]\tvalid_0's multi_logloss: 1.39137\n",
      "[142]\tvalid_0's multi_logloss: 1.39212\n",
      "[143]\tvalid_0's multi_logloss: 1.39318\n",
      "[144]\tvalid_0's multi_logloss: 1.39373\n",
      "[145]\tvalid_0's multi_logloss: 1.39425\n",
      "[146]\tvalid_0's multi_logloss: 1.39519\n",
      "[147]\tvalid_0's multi_logloss: 1.39602\n",
      "[148]\tvalid_0's multi_logloss: 1.39675\n",
      "[149]\tvalid_0's multi_logloss: 1.3975\n",
      "[150]\tvalid_0's multi_logloss: 1.39829\n",
      "[151]\tvalid_0's multi_logloss: 1.39886\n",
      "[152]\tvalid_0's multi_logloss: 1.39991\n",
      "[153]\tvalid_0's multi_logloss: 1.40055\n",
      "[154]\tvalid_0's multi_logloss: 1.40126\n",
      "[155]\tvalid_0's multi_logloss: 1.40169\n",
      "[156]\tvalid_0's multi_logloss: 1.40245\n",
      "[157]\tvalid_0's multi_logloss: 1.40316\n",
      "[158]\tvalid_0's multi_logloss: 1.40411\n",
      "[159]\tvalid_0's multi_logloss: 1.40475\n",
      "[160]\tvalid_0's multi_logloss: 1.40534\n",
      "[161]\tvalid_0's multi_logloss: 1.40626\n",
      "[162]\tvalid_0's multi_logloss: 1.40713\n",
      "[163]\tvalid_0's multi_logloss: 1.40792\n",
      "[164]\tvalid_0's multi_logloss: 1.40874\n",
      "[165]\tvalid_0's multi_logloss: 1.40941\n",
      "[166]\tvalid_0's multi_logloss: 1.41043\n",
      "[167]\tvalid_0's multi_logloss: 1.41114\n",
      "[168]\tvalid_0's multi_logloss: 1.41254\n",
      "[169]\tvalid_0's multi_logloss: 1.41355\n",
      "[170]\tvalid_0's multi_logloss: 1.41463\n",
      "[171]\tvalid_0's multi_logloss: 1.41587\n",
      "[172]\tvalid_0's multi_logloss: 1.41668\n",
      "[173]\tvalid_0's multi_logloss: 1.41781\n",
      "[174]\tvalid_0's multi_logloss: 1.41932\n",
      "[175]\tvalid_0's multi_logloss: 1.42013\n",
      "[176]\tvalid_0's multi_logloss: 1.42113\n",
      "[177]\tvalid_0's multi_logloss: 1.42232\n",
      "[178]\tvalid_0's multi_logloss: 1.4234\n",
      "[179]\tvalid_0's multi_logloss: 1.42437\n",
      "[180]\tvalid_0's multi_logloss: 1.42539\n",
      "[181]\tvalid_0's multi_logloss: 1.42636\n",
      "[182]\tvalid_0's multi_logloss: 1.42724\n",
      "[183]\tvalid_0's multi_logloss: 1.42786\n",
      "[184]\tvalid_0's multi_logloss: 1.42891\n",
      "[185]\tvalid_0's multi_logloss: 1.42986\n",
      "[186]\tvalid_0's multi_logloss: 1.43109\n",
      "[187]\tvalid_0's multi_logloss: 1.43231\n",
      "[188]\tvalid_0's multi_logloss: 1.43346\n",
      "[189]\tvalid_0's multi_logloss: 1.43426\n",
      "[190]\tvalid_0's multi_logloss: 1.43522\n",
      "[191]\tvalid_0's multi_logloss: 1.43646\n",
      "[192]\tvalid_0's multi_logloss: 1.43729\n",
      "[193]\tvalid_0's multi_logloss: 1.43872\n",
      "[194]\tvalid_0's multi_logloss: 1.44016\n",
      "[195]\tvalid_0's multi_logloss: 1.44145\n",
      "[196]\tvalid_0's multi_logloss: 1.44284\n",
      "[197]\tvalid_0's multi_logloss: 1.44385\n",
      "[198]\tvalid_0's multi_logloss: 1.44527\n",
      "[199]\tvalid_0's multi_logloss: 1.44653\n",
      "[200]\tvalid_0's multi_logloss: 1.44775\n",
      "[201]\tvalid_0's multi_logloss: 1.44888\n",
      "[202]\tvalid_0's multi_logloss: 1.45004\n",
      "[203]\tvalid_0's multi_logloss: 1.45121\n",
      "[204]\tvalid_0's multi_logloss: 1.45236\n",
      "[205]\tvalid_0's multi_logloss: 1.45386\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's multi_logloss: 1.37738\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_wrapper = LGBMClassifier(n_estimators=400)\n",
    "\n",
    "evals = [(X_test_tfidf_vect, y_test)]\n",
    "lgbm_wrapper.fit(X_train_tfidf_vect, y_train, early_stopping_rounds=400, eval_metric='logloss',\n",
    "                eval_set = evals, verbose=True)\n",
    "preds = lgbm_wrapper.predict(X_test_tfidf_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = accuracy_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'xgboost' has no attribute 'XGBClassifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e85ed1f331d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mxgb_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'xgboost' has no attribute 'XGBClassifier'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=400, learning_rate=0.1, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'XGBClassifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d814ebf0edc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mwgb_wrapper\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mevals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_tfidf_vect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'XGBClassifier'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "wgb_wrapper=XGBClassifier(n_estimators=400, learning_rate=0.1, max_depth=3)\n",
    "\n",
    "evals = [(X_test_tfidf_vect, y_test)]\n",
    "\n",
    "wgb_wrapper.fit(X_train_tfidf_vect, y_train, early_stopping_rounds=50, eval_metric='mlogloss', eval_set = evals, verbose=True)\n",
    "\n",
    "preds = wgb_wrapper.predict(X_test_tfidf_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive</th>\n",
       "      <th>svm</th>\n",
       "      <th>RF</th>\n",
       "      <th>DT</th>\n",
       "      <th>VT</th>\n",
       "      <th>lgbm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.776118</td>\n",
       "      <td>0.695035</td>\n",
       "      <td>0.50769</td>\n",
       "      <td>0.482873</td>\n",
       "      <td>0.723579</td>\n",
       "      <td>0.606612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Naive       svm       RF        DT        VT      lgbm\n",
       "0  0.776118  0.695035  0.50769  0.482873  0.723579  0.606612"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Naive' : [Naive], 'svm':[svm], 'RF':[RF], 'DT':[DT], 'VT':[VT], 'lgbm':[lgbm]})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "dcl = DecisionTreeClassifier(min_samples_leaf=6)\n",
    "mod = MultinomialNB(alpha=0.02)\n",
    "\n",
    "# 개별 모델을 소프트 보팅 기반의 앙상블 모델로 구현한 분류기\n",
    "vo_clf = VotingClassifier(estimators=[('DCL', dcl), ('MNB', mod)], voting='soft')\n",
    "\n",
    "#VotingClassifier 학습/예측/평가.\n",
    "vo_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = vo_clf.predict(X_test_tfidf_vect)\n",
    "print('Voting 분류기 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
